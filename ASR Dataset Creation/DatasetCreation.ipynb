{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf4064c-724e-4497-a945-59e1d2d0984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "from silero_vad import get_speech_timestamps, read_audio, save_audio\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50df2848-9e34-46ae-8c63-cbab5aa7a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/ASUS/Desktop/FYP/Codes/whisper/Fast Whisper/faster-whisper/faster_whisper\")  # Replace with actual path\n",
    "\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1871457-4d12-4def-a349-933ce2da1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"C:/Users/ASUS/Desktop/FYP/Codes/whisper/Fast Whisper/ctranslate2_model_4\"\n",
    "\n",
    "# Initialize Whisper model\n",
    "model = WhisperModel(MODEL_PATH, device=\"cuda\", compute_type=\"float32\",num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15ac139-53c3-4e97-abd5-9281101e4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio_segment(segment, sample_rate, file_name):\n",
    "    \"\"\"Save audio segment as a .wav file.\"\"\"\n",
    "    # Convert PyTorch tensor to NumPy array\n",
    "    if isinstance(segment, torch.Tensor):\n",
    "        segment = segment.numpy()\n",
    "    # Save the audio segment\n",
    "    write(file_name, sample_rate, segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e54da6-d4e2-4425-a8e9-0151e230b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_using_vad(audio_path, output_folder):\n",
    "    \"\"\"Split audio using Silero VAD and process near 10-second speech segments.\"\"\"\n",
    "    \n",
    "    # Load Silero VAD model\n",
    "    modelVAD, utils = torch.hub.load('snakers4/silero-vad', 'silero_vad', force_reload=True)\n",
    "    get_speech_timestamps, *_ = utils\n",
    "\n",
    "    # Read the audio file\n",
    "    audio = read_audio(audio_path, sampling_rate=16000)\n",
    "\n",
    "    # Run VAD to get speech timestamps\n",
    "    speech_timestamps = get_speech_timestamps(audio, modelVAD, sampling_rate=16000)\n",
    "\n",
    "    output_tsv_path = f\"{output_folder}/transcriptions.tsv\"\n",
    "    \n",
    "    min_duration = 5 * 16000  \n",
    "    current_segment = []  \n",
    "    accumulated_length = 0 \n",
    "    i=262\n",
    "    for timestamp in speech_timestamps:\n",
    "        start, end = timestamp['start'], timestamp['end']\n",
    "        segment = audio[start:end]  \n",
    "        segment_length = end - start\n",
    "\n",
    "        # Accumulate segments until we reach ~10s\n",
    "        current_segment.append(segment)\n",
    "        accumulated_length += segment_length\n",
    "\n",
    "        if accumulated_length >= min_duration or timestamp == speech_timestamps[-1]: \n",
    "            # Merge accumulated segments\n",
    "            merged_segment = torch.cat(current_segment, dim=0)  \n",
    "            audio_np = merged_segment.cpu().numpy()\n",
    "\n",
    "            # Transcribe\n",
    "            segments, _ = model.transcribe(audio_np, vad_filter=False)\n",
    "            transcription = \" \".join(seg.text for seg in segments)\n",
    "\n",
    "            print(\"Transcription:\", transcription)\n",
    "            output_file_name = f\"{i+1}.wav\"\n",
    "            output_path = f\"{output_folder}/{output_file_name}\"\n",
    "            save_audio_segment(merged_segment, 16000, output_path)\n",
    "            i+=1\n",
    "            # Save transcription\n",
    "            with open(output_tsv_path, \"a\", newline=\"\", encoding=\"utf-8\") as tsv_file:\n",
    "                writer = csv.writer(tsv_file, delimiter=\"\\t\")\n",
    "                writer.writerow([output_file_name,transcription])\n",
    "\n",
    "            # Reset buffer for next segment\n",
    "            current_segment = []\n",
    "            accumulated_length = 0\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd3448fa-be5b-4477-ab52-75646a9f5dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to C:\\Users\\ASUS/.cache\\torch\\hub\\master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: අපගේ ගුරු දේවෝතම කල්‍යාණ මිත්‍ර ගෞරවනය පින්වත් ලොකු ස්වාමීන් වහන්සේට\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_path = \"C:/Users/ASUS/Desktop/FYP/Codes/whisper/testF8.flac\"\n",
    "output_folder = \"C:/Users/ASUS/Desktop/FYP/Codes/whisper/AugmentResultMeasure\"\n",
    "split_audio_using_vad(audio_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5b588-baa0-43c4-9b40-2dc98ba713f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
