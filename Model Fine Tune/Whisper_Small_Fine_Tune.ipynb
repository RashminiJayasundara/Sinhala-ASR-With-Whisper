{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbR8PPiwIb46"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMa3qjFtIl0L"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUVh2te9Il3X"
      },
      "outputs": [],
      "source": [
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iH5XxuvWIl6O"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMlVI-mxIl9X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor, WhisperFeatureExtractor,WhisperTokenizer,Seq2SeqTrainingArguments,Seq2SeqTrainer\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "from datasets import Dataset,load_from_disk\n",
        "import torchaudio\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "import numpy as np\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "681xaz98ImAS"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZrWE_k4ImDI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjAi5XZfImGJ"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/asr_sinhala'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cNvXh3mI0gj"
      },
      "outputs": [],
      "source": [
        "tsv_file = os.path.join(data_path, 'trainF.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W13C6LAeI0jx"
      },
      "outputs": [],
      "source": [
        "test_tsv_file = os.path.join(data_path, 'spontaniousTest.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDgG044lI0mt"
      },
      "outputs": [],
      "source": [
        "with open(tsv_file, 'r') as file:\n",
        "    reader = csv.reader(file, delimiter='\\t')\n",
        "    df = pd.DataFrame(reader)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaDygS8sI0p4"
      },
      "outputs": [],
      "source": [
        "with open(test_tsv_file, 'r') as file:\n",
        "    reader = csv.reader(file, delimiter='\\t')\n",
        "    df_test = pd.DataFrame(reader)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGYvSXyzI0s0"
      },
      "outputs": [],
      "source": [
        "audio_data_path =  '/content/drive/MyDrive/asr_sinhala/audioDataF'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCGv6rXLI0wB"
      },
      "outputs": [],
      "source": [
        "audio_data_path_test =  '/content/drive/MyDrive/asr_sinhala/SponAudio'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNU-OB1OI0zh"
      },
      "outputs": [],
      "source": [
        "data_dict = {\n",
        "    'audio': [os.path.join(audio_data_path, f\"{filename}.flac\") for filename in df[0]],\n",
        "    'text': df[2],\n",
        "    'speaker_id': df[1]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqhtaB0VJFjc"
      },
      "outputs": [],
      "source": [
        "data_dict_test = {\n",
        "    'audio': [os.path.join(audio_data_path_test, f\"{filename}.flac\") for filename in df_test[0]],\n",
        "    'text': df_test[2],\n",
        "    'speaker_id': df_test[1]  # Speaker ID, if needed for further processing\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWxjKiryJFmU"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset.from_dict(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KuMuTLQJFpK"
      },
      "outputs": [],
      "source": [
        "test_dataset=Dataset.from_dict(data_dict_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjI-mVRUJFsN"
      },
      "outputs": [],
      "source": [
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4zIxbWpJFv2"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperTokenizer\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Sinhala\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJuGlvlQJR_e"
      },
      "outputs": [],
      "source": [
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Sinhala\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7jJwvndJSCq"
      },
      "outputs": [],
      "source": [
        "def tokenize_transcriptions(examples):\n",
        "    return processor.tokenizer(examples['text'], padding=True, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYf3XbAxJSFn"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(tokenize_transcriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff6GC3bZJSJS"
      },
      "outputs": [],
      "source": [
        "tokenized_testset = test_dataset.map(tokenize_transcriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaxexoThJSLe"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(batch):\n",
        "\n",
        "    audio_path = batch['audio']\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "    input_features = feature_extractor(waveform.squeeze().numpy(), sampling_rate=sample_rate).input_features[0]\n",
        "    labels = tokenizer(batch[\"text\"]).input_ids\n",
        "\n",
        "    return {\"input_features\": input_features, \"labels\": labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH8dxCvLJiio"
      },
      "outputs": [],
      "source": [
        "processed_dataset = tokenized_dataset.map(preprocess_data, remove_columns=[\"audio\", \"speaker_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFszHFE7Jil3"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/My Drive/asr_sinhala/ProcessedData/trained_dataset_f'\n",
        "processed_dataset.save_to_disk(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5li0uooJipU"
      },
      "outputs": [],
      "source": [
        "processed_test_dataset = tokenized_testset.map(preprocess_data, remove_columns=[\"audio\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTVQ_-SMJu-L"
      },
      "outputs": [],
      "source": [
        "save_path_test = '/content/drive/My Drive/asr_sinhala/ProcessedData/test_dataset_s'\n",
        "processed_test_dataset.save_to_disk(save_path_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JKwKGIbJvBv"
      },
      "outputs": [],
      "source": [
        "processed_dataset = load_from_disk(save_path)\n",
        "processed_test_dataset = load_from_disk(save_path_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2OOi5POJ6Dj"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "    decoder_start_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "      input_features = []\n",
        "      for feature in features:\n",
        "          if \"input_features\" not in feature:\n",
        "              print(\"Warning: 'input_features' not found in feature:\", feature)\n",
        "              continue\n",
        "          input_features.append({\"input_features\": feature[\"input_features\"]})\n",
        "\n",
        "      batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "      label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features if \"labels\" in feature]\n",
        "      if len(label_features) == 0:\n",
        "          raise ValueError(\"No valid 'labels' found in the features.\")\n",
        "\n",
        "      labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "      labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "      if labels.size(1) > 0 and (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
        "          labels = labels[:, 1:]\n",
        "\n",
        "      batch[\"labels\"] = labels\n",
        "\n",
        "      return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVI0R_bUJ6G-"
      },
      "outputs": [],
      "source": [
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9Fhqm8FKIXo"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
        "    processor=processor,\n",
        "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KS881W8KIaz"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"wer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caOlGESNKId0"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDCLS7kLKIgm"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-small-specaugment-sinhala\",\n",
        "    logging_steps=100,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=1e-5,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_steps=500,\n",
        "    num_train_epochs=3,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    per_device_eval_batch_size=32,\n",
        "    predict_with_generate=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVxf_INJKIjk"
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=processed_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    eval_dataset=processed_test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAvuPvhNKInD"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2wTXHO6Kj78"
      },
      "outputs": [],
      "source": [
        "model.push_to_hub(\"RRashmini/whisper-small-sinhala\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56946gjlKj_k"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(eval_dataset=processed_test_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
